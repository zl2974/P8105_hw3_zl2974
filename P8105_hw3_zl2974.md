Untitled
================
Jeffrey Liang
10/02/2020

# Problem 1

``` r
library(p8105.datasets)
```

    ## Warning: package 'p8105.datasets' was built under R version 4.0.2

``` r
data("instacart")
str(instacart)
```

    ## tibble [1,384,617 × 15] (S3: tbl_df/tbl/data.frame)
    ##  $ order_id              : int [1:1384617] 1 1 1 1 1 1 1 1 36 36 ...
    ##  $ product_id            : int [1:1384617] 49302 11109 10246 49683 43633 13176 47209 22035 39612 19660 ...
    ##  $ add_to_cart_order     : int [1:1384617] 1 2 3 4 5 6 7 8 1 2 ...
    ##  $ reordered             : int [1:1384617] 1 1 0 0 1 0 0 1 0 1 ...
    ##  $ user_id               : int [1:1384617] 112108 112108 112108 112108 112108 112108 112108 112108 79431 79431 ...
    ##  $ eval_set              : chr [1:1384617] "train" "train" "train" "train" ...
    ##  $ order_number          : int [1:1384617] 4 4 4 4 4 4 4 4 23 23 ...
    ##  $ order_dow             : int [1:1384617] 4 4 4 4 4 4 4 4 6 6 ...
    ##  $ order_hour_of_day     : int [1:1384617] 10 10 10 10 10 10 10 10 18 18 ...
    ##  $ days_since_prior_order: int [1:1384617] 9 9 9 9 9 9 9 9 30 30 ...
    ##  $ product_name          : chr [1:1384617] "Bulgarian Yogurt" "Organic 4% Milk Fat Whole Milk Cottage Cheese" "Organic Celery Hearts" "Cucumber Kirby" ...
    ##  $ aisle_id              : int [1:1384617] 120 108 83 83 95 24 24 21 2 115 ...
    ##  $ department_id         : int [1:1384617] 16 16 4 4 15 4 4 16 16 7 ...
    ##  $ aisle                 : chr [1:1384617] "yogurt" "other creams cheeses" "fresh vegetables" "fresh vegetables" ...
    ##  $ department            : chr [1:1384617] "dairy eggs" "dairy eggs" "produce" "produce" ...
    ##  - attr(*, "spec")=
    ##   .. cols(
    ##   ..   order_id = col_integer(),
    ##   ..   product_id = col_integer(),
    ##   ..   add_to_cart_order = col_integer(),
    ##   ..   reordered = col_integer(),
    ##   ..   user_id = col_integer(),
    ##   ..   eval_set = col_character(),
    ##   ..   order_number = col_integer(),
    ##   ..   order_dow = col_integer(),
    ##   ..   order_hour_of_day = col_integer(),
    ##   ..   days_since_prior_order = col_integer(),
    ##   ..   product_name = col_character(),
    ##   ..   aisle_id = col_integer(),
    ##   ..   department_id = col_integer(),
    ##   ..   aisle = col_character(),
    ##   ..   department = col_character()
    ##   .. )

``` r
instacart %>% 
  count(aisle,name = "n_count") %>% 
  arrange(desc(n_count))
```

    ## # A tibble: 134 x 2
    ##    aisle                         n_count
    ##    <chr>                           <int>
    ##  1 fresh vegetables               150609
    ##  2 fresh fruits                   150473
    ##  3 packaged vegetables fruits      78493
    ##  4 yogurt                          55240
    ##  5 packaged cheese                 41699
    ##  6 water seltzer sparkling water   36617
    ##  7 milk                            32644
    ##  8 chips pretzels                  31269
    ##  9 soy lactosefree                 26240
    ## 10 bread                           23635
    ## # … with 124 more rows

``` r
instacart %>% 
  group_by(aisle) %>% 
  filter(n()>1e+4) %>%
  mutate(counts = n(),
         aisle = forcats::fct_reorder(as.factor(aisle),counts,max)) %>% 
  ggplot(aes(y = aisle,fill = aisle)) +
  geom_bar()+
  scale_x_continuous(trans = "sqrt")+
  theme(legend.position = "none")
```

<img src="P8105_hw3_zl2974_files/figure-gfm/p1_exploring-1.png" width="90%" />

``` r
for (aisle_ in c("baking ingredients","dog food care","packaged vegetables fruits")){
instacart %>% 
  filter(aisle %in% c(aisle_)) %>%
  count(aisle,product_name) %>% 
  slice_max(n,n=3) %>% 
  left_join(instacart) %>% 
    janitor::tabyl(aisle,product_name) %>% 
    print()
}
```

    ## Joining, by = c("aisle", "product_name")

    ##               aisle Cane Sugar Light Brown Sugar Pure Baking Soda
    ##  baking ingredients        336               499              387

    ## Joining, by = c("aisle", "product_name")

    ##          aisle Organix Chicken & Brown Rice Recipe Small Dog Biscuits
    ##  dog food care                                  28                 26
    ##  Snack Sticks Chicken & Rice Recipe Dog Treats
    ##                                             30

    ## Joining, by = c("aisle", "product_name")

    ##                       aisle Organic Baby Spinach Organic Blueberries
    ##  packaged vegetables fruits                 9784                4966
    ##  Organic Raspberries
    ##                 5546

``` r
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples","Coffee Ice Cream")) %>% 
  group_by(product_name,order_dow) %>% 
  summarise(avg_order_hour_of_day = mean(order_hour_of_day,na.rm = T)) %>% 
  pivot_wider(names_from = order_dow,
              names_prefix = "avg_order_hour_of_day_week_",
              values_from = avg_order_hour_of_day) %>% 
  ungroup() %>% 
  t()
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ##                              [,1]               [,2]              
    ## product_name                 "Coffee Ice Cream" "Pink Lady Apples"
    ## avg_order_hour_of_day_week_0 "13.77419"         "13.44118"        
    ## avg_order_hour_of_day_week_1 "14.31579"         "11.36000"        
    ## avg_order_hour_of_day_week_2 "15.38095"         "11.70213"        
    ## avg_order_hour_of_day_week_3 "15.31818"         "14.25000"        
    ## avg_order_hour_of_day_week_4 "15.21739"         "11.55172"        
    ## avg_order_hour_of_day_week_5 "12.26316"         "12.78431"        
    ## avg_order_hour_of_day_week_6 "13.83333"         "11.93750"

# Problem 2

## Load data

``` r
accelerometer =
  read_csv(here::here("data/accel_data.csv")) %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = starts_with("activity_"),
    names_to = 'min',
    values_to = "activity",
    names_prefix = "activity_"
  ) %>% 
  mutate_at(c("min"),as.numeric) %>% 
  mutate(weekday_vs_weekend = day %in% c("Sunday","Saturday"),
         weekday_vs_weekend=
           case_when(weekday_vs_weekend ~"weekend",
                     !weekday_vs_weekend ~ "weekday") %>% 
           as.factor(),
         week = as.character(week) %>% forcats::fct_relevel(as.character(1:5)),
         day = forcats::fct_relevel(day,c("Monday","Tuesday","Wednesday","Thursday",
                                     "Friday", "Saturday","Sunday"))
         ) %>% 
  group_by(week) %>% 
  arrange(day,.by_group=T) %>% 
  group_by(day_id) %>% 
  mutate(min_week = 1,
         hour_day = cumsum(min_week)%/%60) %>% 
  ungroup(day_id) %>% 
  mutate(min_week=cumsum(min_week),
         hour_week = min_week%/%60) %>% 
  ungroup() %>% 
  select(-day_id) %>% 
  left_join(
    distinct(.,week,day,) %>% 
      ungroup() %>% 
      mutate(day_id = 1,day_id = cumsum(day_id))
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

    ## Joining, by = c("week", "day")

``` r
# TODO: day_id is not in order
str(accelerometer)
```

    ## tibble [50,400 × 9] (S3: tbl_df/tbl/data.frame)
    ##  $ week              : Factor w/ 5 levels "1","2","3","4",..: 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ day               : Factor w/ 7 levels "Monday","Tuesday",..: 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ min               : num [1:50400] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ activity          : num [1:50400] 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ weekday_vs_weekend: Factor w/ 2 levels "weekday","weekend": 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ min_week          : num [1:50400] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ hour_day          : num [1:50400] 0 0 0 0 0 0 0 0 0 0 ...
    ##  $ hour_week         : num [1:50400] 0 0 0 0 0 0 0 0 0 0 ...
    ##  $ day_id            : num [1:50400] 1 1 1 1 1 1 1 1 1 1 ...

``` r
skimr::skim(accelerometer)
```

|                                                  |               |
| :----------------------------------------------- | :------------ |
| Name                                             | accelerometer |
| Number of rows                                   | 50400         |
| Number of columns                                | 9             |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |               |
| Column type frequency:                           |               |
| factor                                           | 3             |
| numeric                                          | 6             |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |               |
| Group variables                                  | None          |

Data summary

**Variable type: factor**

| skim\_variable       | n\_missing | complete\_rate | ordered | n\_unique | top\_counts                                |
| :------------------- | ---------: | -------------: | :------ | --------: | :----------------------------------------- |
| week                 |          0 |              1 | FALSE   |         5 | 1: 10080, 2: 10080, 3: 10080, 4: 10080     |
| day                  |          0 |              1 | FALSE   |         7 | Mon: 7200, Tue: 7200, Wed: 7200, Thu: 7200 |
| weekday\_vs\_weekend |          0 |              1 | FALSE   |         2 | wee: 36000, wee: 14400                     |

**Variable type: numeric**

| skim\_variable | n\_missing | complete\_rate |     mean |       sd | p0 |      p25 |     p50 |      p75 |  p100 | hist  |
| :------------- | ---------: | -------------: | -------: | -------: | -: | -------: | ------: | -------: | ----: | :---- |
| min            |          0 |              1 |   720.50 |   415.70 |  1 |   360.75 |   720.5 |  1080.25 |  1440 | ▇▇▇▇▇ |
| activity       |          0 |              1 |   267.04 |   443.16 |  1 |     1.00 |    74.0 |   364.00 |  8982 | ▇▁▁▁▁ |
| min\_week      |          0 |              1 | 25200.50 | 14549.37 |  1 | 12600.75 | 25200.5 | 37800.25 | 50400 | ▇▇▇▇▇ |
| hour\_day      |          0 |              1 |    11.52 |     6.92 |  0 |     6.00 |    12.0 |    18.00 |    24 | ▇▇▇▇▆ |
| hour\_week     |          0 |              1 |   419.52 |   242.49 |  0 |   210.00 |   420.0 |   630.00 |   840 | ▇▇▇▇▇ |
| day\_id        |          0 |              1 |    18.00 |    10.10 |  1 |     9.00 |    18.0 |    27.00 |    35 | ▇▇▇▇▇ |

 The original data is a “wider” format data with 35 x 1443 dimension. In
order to make the data compatible with machine, pivot\_long() is used to
make the *activity*\*\_ of all subjects into columns of *min and
activity*. Following instruction, weekend vs weekday’s variable is build
on *day\_id* and result into a 50400 x 9 dataset.

  - Traditional analyses of accelerometer data focus on the total
    activity over the day. Using your tidied dataset, aggregate accross
    minutes to create a total activity variable for each day, and create
    a table showing these totals. Are any trends apparent?

<!-- end list -->

``` r
accelerometer %>% 
  group_by(week,day) %>% 
  summarise(daily_activity = sum(activity,na.rm=T)) %>% 
  pivot_wider(names_from = week,
              names_prefix = "week ",
              values_from = daily_activity) %>% 
  knitr::kable()
```

| day       |    week 1 | week 2 | week 3 | week 4 | week 5 |
| :-------- | --------: | -----: | -----: | -----: | -----: |
| Monday    |  78828.07 | 295431 | 685910 | 409450 | 389080 |
| Tuesday   | 307094.24 | 423245 | 381507 | 319568 | 367824 |
| Wednesday | 340115.01 | 440962 | 468869 | 434460 | 445366 |
| Thursday  | 355923.64 | 474048 | 371230 | 340291 | 549658 |
| Friday    | 480542.62 | 568839 | 467420 | 154049 | 620860 |
| Saturday  | 376254.00 | 607175 | 382928 |   1440 |   1440 |
| Sunday    | 631105.00 | 422018 | 467052 | 260617 | 138421 |

``` r
# TODO: hwo to make this table clean and nice? definatly not janitor, this is continuous
```

  - Accelerometer data allows the inspection activity over the course of
    the day. Make a single-panel plot that shows the 24-hour activity
    time courses for each day and use color to indicate day of the week.
    Describe in words any patterns or conclusions you can make based on
    this graph. Problem 3

<!-- end list -->

``` r
accelerometer %>% 
  group_by(week,day_id,hour_day) %>% 
  summarise(activity_hr = sum(activity,na.rm=T)) %>% 
  ggplot(aes(x=hour_day,y=day_id,fill=activity_hr))+
  geom_tile(aes(height = .93,width = .93),size = 2, stat="identity")+
  scale_y_continuous(breaks = seq(3,31,7),
                   labels = c(str_c("week",c(1:5))),
                   position = "left",
                   name = '')+
  scale_x_continuous(breaks = seq(0,24,6),
                     name = "Hour of day")+
  theme(legend.position = "right")+
  viridis::scale_fill_viridis(option = "C",
                              name = "Hourly Activities")
```

    ## `summarise()` regrouping output by 'week', 'day_id' (override with `.groups` argument)

<img src="P8105_hw3_zl2974_files/figure-gfm/activity_plot-1.png" width="90%" />

# Problem 3

``` r
data("ny_noaa")
tryCatch(
  {ny_noaa_tidy = read_csv(here::here("data/ny_noaa_tidy.csv"))},
  error ={
    ny_noaa_tidy = ny_noaa %>% 
    separate(date,
             into=c("year","month","day"),sep="-") %>%
    mutate(across(year:tmin,as.numeric)) %>% 
    mutate(
      snow = case_when(
      snow <0 ~0))
  write_csv(ny_noaa_tidy,here::here("data/ny_noaa_tidy.csv"))})
skimr::skim(ny_noaa_tidy)
```

  - Make a two-panel plot showing the average max temperature in January
    and in July in each station across years. Is there any observable /
    interpretable structure? Any outliers?

<!-- end list -->

``` r
ny_noaa_tidy %>% 
  filter(as.numeric(month) %in% c(1,7)) %>% 
  mutate(day = as.factor(day),
         month = month.name[month]) %>% 
  ggplot(aes(x = day, y = tmax, color = month)) +
  geom_boxplot(outlier.size = 0.5,
               outlier.alpha = 0.5)+
  #scale_color_viridis_d(option = "E",name = "Month")+
  facet_wrap(.~month,ncol = 1)+
  scale_y_continuous(position = "right",
                     name = "Highest Temperature of the Day")+
  scale_x_discrete(breaks = seq(1,31,5),
                   name = "Day of Month")
```
